{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Information from Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os \n",
    "import sys\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "import pprint\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk.grammar import DependencyGrammar\n",
    "from nltk.parse import CoreNLPParser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Extraction Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ie_preprocess(document):\n",
    "    sentences = nltk.sent_tokenize(document)\n",
    "    print(sentences)\n",
    "    words = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    print(words)\n",
    "    tagged_sentences = [nltk.pos_tag(word) for word in words]\n",
    "    print(tagged_sentences)\n",
    "\n",
    "    \n",
    "    return tagged_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The oxygen must be maintained at temperature of 297 degrees below zero to remain liquid.']\n",
      "[['The', 'oxygen', 'must', 'be', 'maintained', 'at', 'temperature', 'of', '297', 'degrees', 'below', 'zero', 'to', 'remain', 'liquid', '.']]\n",
      "[[('The', 'DT'), ('oxygen', 'NN'), ('must', 'MD'), ('be', 'VB'), ('maintained', 'VBN'), ('at', 'IN'), ('temperature', 'NN'), ('of', 'IN'), ('297', 'CD'), ('degrees', 'NNS'), ('below', 'IN'), ('zero', 'NN'), ('to', 'TO'), ('remain', 'VB'), ('liquid', 'JJ'), ('.', '.')]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('The', 'DT'),\n",
       "  ('oxygen', 'NN'),\n",
       "  ('must', 'MD'),\n",
       "  ('be', 'VB'),\n",
       "  ('maintained', 'VBN'),\n",
       "  ('at', 'IN'),\n",
       "  ('temperature', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('297', 'CD'),\n",
       "  ('degrees', 'NNS'),\n",
       "  ('below', 'IN'),\n",
       "  ('zero', 'NN'),\n",
       "  ('to', 'TO'),\n",
       "  ('remain', 'VB'),\n",
       "  ('liquid', 'JJ'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text='The oxygen must be maintained at temperature of 297 degrees below zero to remain liquid.'\n",
    "pos=ie_preprocess(text)\n",
    "\n",
    "pos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP The/DT oxygen/NN)\n",
      "  must/MD\n",
      "  be/VB\n",
      "  maintained/VBN\n",
      "  at/IN\n",
      "  (NP temperature/NN)\n",
      "  of/IN\n",
      "  297/CD\n",
      "  degrees/NNS\n",
      "  below/IN\n",
      "  (NP zero/NN)\n",
      "  to/TO\n",
      "  remain/VB\n",
      "  liquid/JJ\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "cs = cp.parse(pos[0])\n",
    "print (cs)\n",
    "# cs.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  The/DT\n",
      "  oxygen/NN\n",
      "  must/MD\n",
      "  be/VB\n",
      "  maintained/VBN\n",
      "  at/IN\n",
      "  temperature/NN\n",
      "  of/IN\n",
      "  297/CD\n",
      "  degrees/NNS\n",
      "  below/IN\n",
      "  zero/NN\n",
      "  to/TO\n",
      "  remain/VB\n",
      "  liquid/JJ\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "ner=nltk.ne_chunk(pos[0], binary=False)\n",
    "print (ner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Oxygen', 'NN', 'B-NP'),\n",
      " ('must', 'MD', 'O'),\n",
      " ('be', 'VB', 'O'),\n",
      " ('maintained', 'VBN', 'O'),\n",
      " ('at', 'IN', 'O'),\n",
      " ('297', 'CD', 'O'),\n",
      " ('degrees', 'NNS', 'O'),\n",
      " ('below', 'IN', 'O'),\n",
      " ('zero', 'NN', 'B-NP'),\n",
      " ('to', 'TO', 'O'),\n",
      " ('remain', 'VB', 'O'),\n",
      " ('liquid', 'JJ', 'O'),\n",
      " ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "from pprint import pprint\n",
    "iob_tagged = tree2conlltags(cs)\n",
    "pprint(iob_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.corpus.reader.ieer.IEERDocument'>\n",
      "<class 'collections.defaultdict'>\n",
      "[ORG: 'WHYY'] 'in' [LOC: 'Philadelphia']\n",
      "<class 'nltk.corpus.reader.ieer.IEERDocument'>\n",
      "<class 'collections.defaultdict'>\n",
      "[ORG: 'McGlashan &AMP; Sarrail'] 'firm in' [LOC: 'San Mateo']\n",
      "<class 'nltk.corpus.reader.ieer.IEERDocument'>\n",
      "<class 'collections.defaultdict'>\n",
      "[ORG: 'Freedom Forum'] 'in' [LOC: 'Arlington']\n",
      "<class 'nltk.corpus.reader.ieer.IEERDocument'>\n",
      "<class 'collections.defaultdict'>\n",
      "[ORG: 'Brookings Institution'] ', the research group in' [LOC: 'Washington']\n",
      "<class 'nltk.corpus.reader.ieer.IEERDocument'>\n",
      "<class 'collections.defaultdict'>\n",
      "[ORG: 'Idealab'] ', a self-described business incubator based in' [LOC: 'Los Angeles']\n",
      "<class 'collections.defaultdict'>\n",
      "[ORG: 'Open Text'] ', based in' [LOC: 'Waterloo']\n",
      "<class 'nltk.corpus.reader.ieer.IEERDocument'>\n",
      "<class 'collections.defaultdict'>\n",
      "[ORG: 'WGBH'] 'in' [LOC: 'Boston']\n",
      "<class 'nltk.corpus.reader.ieer.IEERDocument'>\n",
      "<class 'nltk.corpus.reader.ieer.IEERDocument'>\n",
      "<class 'nltk.corpus.reader.ieer.IEERDocument'>\n",
      "<class 'nltk.corpus.reader.ieer.IEERDocument'>\n",
      "<class 'collections.defaultdict'>\n",
      "[ORG: 'Bastille Opera'] 'in' [LOC: 'Paris']\n",
      "<class 'nltk.corpus.reader.ieer.IEERDocument'>\n",
      "<class 'collections.defaultdict'>\n",
      "[ORG: 'Omnicom'] 'in' [LOC: 'New York']\n",
      "<class 'collections.defaultdict'>\n",
      "[ORG: 'DDB Needham'] 'in' [LOC: 'New York']\n",
      "<class 'collections.defaultdict'>\n",
      "[ORG: 'Kaplan Thaler Group'] 'in' [LOC: 'New York']\n",
      "<class 'collections.defaultdict'>\n",
      "[ORG: 'BBDO South'] 'in' [LOC: 'Atlanta']\n",
      "<class 'collections.defaultdict'>\n",
      "[ORG: 'Georgia-Pacific'] 'in' [LOC: 'Atlanta']\n",
      "<class 'nltk.corpus.reader.ieer.IEERDocument'>\n",
      "<class 'nltk.corpus.reader.ieer.IEERDocument'>\n"
     ]
    }
   ],
   "source": [
    "IN = re.compile(r'.*\\bin\\b(?!\\b.+ing)')\n",
    "for doc in nltk.corpus.ieer.parsed_docs('NYT_19980315'):\n",
    "    print(type(doc))\n",
    "    for rel in nltk.sem.extract_rels('ORG', 'LOC', doc, corpus = 'ieer', pattern = IN):\n",
    "        print(type(rel))\n",
    "        print(nltk.sem.rtuple(rel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel=nltk.sem.extract_rels('ORG', 'LOC', doc=doc, corpus = 'ieer', pattern = IN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28832/4047859320.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\dowdj\\OneDrive\\Documents\\GitHub\\NLP-Training\\nltk\\venv\\lib\\site-packages\\nltk\\sem\\relextract.py\u001b[0m in \u001b[0;36mrtuple\u001b[1;34m(reldict, lcon, rcon)\u001b[0m\n\u001b[0;32m    268\u001b[0m     \"\"\"\n\u001b[0;32m    269\u001b[0m     items = [\n\u001b[1;32m--> 270\u001b[1;33m         \u001b[0mclass_abbrev\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreldict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"subjclass\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m         \u001b[0mreldict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"subjtext\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[0mreldict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"filler\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "nltk.sem.rtuple(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "IN = re.compile(r'.*\\bin\\b(?!\\b.+ing)')\n",
    "for doc in nltk.corpus.ieer.parsed_docs('NYT_19980315'):\n",
    "    for rel in nltk.sem.extract_rels('ORG', 'LOC', doc, corpus = 'ieer',\n",
    "    pattern = IN):\n",
    "        print(nltk.sem.rtuple(rel))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a7267efbf6fadf323e6919ae49483da79d63800eb323ed7cd34ea2e36e2688e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
