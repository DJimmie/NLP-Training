{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os \n",
    "import sys\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "import pprint\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk.grammar import DependencyGrammar\n",
    "from nltk.parse import CoreNLPParser\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(stemmer_on=False):\n",
    "    with open(\"../data/t1.txt\") as f:   \n",
    "        text = f.read()\n",
    "\n",
    "    sentences=sent_tokenize(text.lower())\n",
    "    if stemmer_on==True:\n",
    "        p=LancasterStemmer()\n",
    "        # l=WordNetLemmatizer()\n",
    "        stemmed_sentences=[]\n",
    "        for a in sentences:\n",
    "            stemmed_sentences.append(' '.join([p.stem(w) for w in word_tokenize(a)]))\n",
    "            # stemmed_sentences.append(' '.join([l.lemmatize(w,pos='v') for w in word_tokenize(a)]))\n",
    "            # print(stemmed_sentences)\n",
    "            sentences=stemmed_sentences\n",
    "\n",
    "    print(f'Number of sentences:{len(sentences)}')\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vector1, vector2):\n",
    "    vector1 = np.array(vector1)\n",
    "    vector2 = np.array(vector2)\n",
    "    return np.dot(vector1, vector2) / (np.sqrt(np.sum(vector1**2)) * np.sqrt(np.sum(vector2**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(data,headers):\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns=headers\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity of 2 vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = (5,0,5,6,3,9,8,7,5,6)\n",
    "d2 = (3,0,2,4,6,9,8,5,2,1)\n",
    "d1 = np.array(d1)\n",
    "d2 = np.array(d2)\n",
    "print(d1)\n",
    "print(d2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(d1, d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding cosine similarity between documents in a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = get_text(stemmer_on=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.Series(text)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = CountVectorizer(stop_words='english')\n",
    "# bow_matrix = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer(norm='l2',stop_words='english',ngram_range=(1,1))\n",
    "bow_matrix=vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_matrix\n",
    "print(type(bow_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_count = vectorizer.get_feature_names()\n",
    "feature_names_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array_count = bow_matrix.toarray()\n",
    "features_array_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_data=[]\n",
    "for i in range(bow_matrix.shape[0]):\n",
    "    for j in range(i + 1, bow_matrix.shape[0]):\n",
    "        cs=cosine_similarity(bow_matrix.toarray()[i], bow_matrix.toarray()[j])\n",
    "        cs_angle=round(math.degrees(math.acos(cs)),3\n",
    "        )\n",
    "\n",
    "        cs_data.append((i,j,cs_angle))\n",
    "\n",
    "        # print(f\"The cosine similarity between the documents {i}, and {j} is: {cs} (angle: {cs_angle} degrees)\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_df=get_dataframe(cs_data,['sentence_a','sentence_b', 'cs_angle'])\n",
    "\n",
    "cs_df.sort_values(by=['sentence_a','cs_angle'], inplace=True)\n",
    "cs_df[(cs_df.sentence_b>2) & (cs_df.sentence_a<3)]\n",
    "# cs_df[(cs_df.cs_angle<90.00) & (cs_df.sentence_b>17) & (cs_df.sentence_a<=17)]\n",
    "# cs_df[(cs_df.cs_angle<90.00)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[cs_df.sentence_b]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a7267efbf6fadf323e6919ae49483da79d63800eb323ed7cd34ea2e36e2688e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
