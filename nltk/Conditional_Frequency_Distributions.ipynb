{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading your own Corpus"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import nltk"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\r\n",
    "corpus_root = 'C:/Users/dowdj/OneDrive/Documents/GitHub/NLP-Training/data'\r\n",
    "wordlists = PlaintextCorpusReader(corpus_root, '.*')\r\n",
    "wordlists.fileids()\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['t1.txt']"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "wordlists.words('t1.txt')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['identify', 'all', 'the', 'categories', ',', 'types', ...]"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "len(wordlists.words('t1.txt'))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conditional Frequency Distributions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from nltk.corpus import brown\r\n",
    "cfd = nltk.ConditionalFreqDist(\r\n",
    "(genre, word)\r\n",
    "for genre in brown.categories()\r\n",
    "for word in brown.words(categories=genre))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "genre_word = [(genre, word)\r\n",
    "for genre in ['news', 'romance']\r\n",
    "for word in brown.words(categories=genre)]\r\n",
    "len(genre_word)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "170576"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "genre_word[:4]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('news', 'The'), ('news', 'Fulton'), ('news', 'County'), ('news', 'Grand')]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "genre_word[-4:]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('romance', 'afraid'),\n",
       " ('romance', 'not'),\n",
       " ('romance', \"''\"),\n",
       " ('romance', '.')]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "cfd = nltk.ConditionalFreqDist(genre_word)\r\n",
    "cfd.conditions()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['news', 'romance']"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "print(cfd['news'])\r\n",
    "print(cfd['romance'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<FreqDist with 14394 samples and 100554 outcomes>\n",
      "<FreqDist with 8452 samples and 70022 outcomes>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "cfd['news'].most_common(20)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('the', 5580),\n",
       " (',', 5188),\n",
       " ('.', 4030),\n",
       " ('of', 2849),\n",
       " ('and', 2146),\n",
       " ('to', 2116),\n",
       " ('a', 1993),\n",
       " ('in', 1893),\n",
       " ('for', 943),\n",
       " ('The', 806),\n",
       " ('that', 802),\n",
       " ('``', 732),\n",
       " ('is', 732),\n",
       " ('was', 717),\n",
       " (\"''\", 702),\n",
       " ('on', 657),\n",
       " ('at', 598),\n",
       " ('with', 545),\n",
       " ('be', 526),\n",
       " ('by', 497)]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "cfd['romance']['war']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "cfd['news']['war']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from nltk.corpus import inaugural\r\n",
    "cfd = nltk.ConditionalFreqDist(\r\n",
    "(target, fileid[:4])\r\n",
    "for fileid in inaugural.fileids()\r\n",
    "for w in inaugural.words(fileid)\r\n",
    "for target in ['america', 'citizen']\r\n",
    "if w.lower().startswith(target))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "cfd['america']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "FreqDist({'2017': 35, '1993': 33, '1997': 31, '2005': 30, '1921': 24, '1973': 23, '1985': 21, '2001': 20, '2013': 19, '1981': 16, ...})"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "cfd.tabulate(conditions=['america', 'citizen'],\r\n",
    "samples=range(10), cumulative=True)\r\n",
    "  "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "        0 1 2 3 4 5 6 7 8 9 \n",
      "america 0 0 0 0 0 0 0 0 0 0 \n",
      "citizen 0 0 0 0 0 0 0 0 0 0 \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generating Random Text with Bigrams"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\r\n",
    "corpus_root = 'C:/Users/dowdj/OneDrive/Documents/GitHub/NLP-Training/data'\r\n",
    "wordlists = PlaintextCorpusReader(corpus_root, '.*')\r\n",
    "wordlists.fileids()\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['t1.txt']"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "def generate_model(cfdist, word, num=30):\r\n",
    "    for i in range(num):\r\n",
    "        print(word, end=' ')\r\n",
    "        word = cfdist[word].max()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "word=wordlists.words()\r\n",
    "word"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['identify', 'all', 'the', 'categories', ',', 'types', ...]"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "bigrams=list(nltk.bigrams(word))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "\r\n",
    "\r\n",
    "cfd = nltk.ConditionalFreqDist(bigrams)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "generate_model(cfd, 'graph')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "graph this is available to each other and in a semantic knowledge graph this is available to each other and in a semantic knowledge graph this is available to each "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "cfd.conditions()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['identify',\n",
       " 'all',\n",
       " 'the',\n",
       " 'categories',\n",
       " ',',\n",
       " 'types',\n",
       " 'things',\n",
       " 'and',\n",
       " 'objects',\n",
       " 'that',\n",
       " 'are',\n",
       " 'important',\n",
       " 'for',\n",
       " 'field',\n",
       " 'we',\n",
       " 'then',\n",
       " 'understand',\n",
       " 'more',\n",
       " 'how',\n",
       " 'they',\n",
       " 'relate',\n",
       " 'to',\n",
       " 'each',\n",
       " 'other',\n",
       " 'what',\n",
       " 'information',\n",
       " 'is',\n",
       " 'available',\n",
       " 'describe',\n",
       " 'them',\n",
       " 'even',\n",
       " 'accurately',\n",
       " '.',\n",
       " 'We',\n",
       " 'call',\n",
       " 'this',\n",
       " '‘',\n",
       " 'conceptual',\n",
       " 'model',\n",
       " ',’',\n",
       " 'in',\n",
       " 'a',\n",
       " 'semantic',\n",
       " 'knowledge',\n",
       " 'graph',\n",
       " 'represented',\n",
       " 'by',\n",
       " 'schema',\n",
       " 'or',\n",
       " 'ontology',\n",
       " 'Since',\n",
       " 'express',\n",
       " 'not',\n",
       " 'only',\n",
       " 'schematically',\n",
       " 'but',\n",
       " 'also',\n",
       " 'above',\n",
       " 'through',\n",
       " 'human',\n",
       " 'language',\n",
       " 'very',\n",
       " 'individually',\n",
       " 'different',\n",
       " 'languages',\n",
       " 'must',\n",
       " 'provide',\n",
       " 'linguistic',\n",
       " '’',\n",
       " 'our',\n",
       " 'The',\n",
       " 'serves',\n",
       " 'label',\n",
       " 'further',\n",
       " 'contextualize',\n",
       " 'individual',\n",
       " 'elements',\n",
       " 'of',\n",
       " 'their',\n",
       " 'instances',\n",
       " 'In',\n",
       " 'made',\n",
       " 'possible',\n",
       " 'controlled',\n",
       " 'vocabularies',\n",
       " 'such',\n",
       " 'as',\n",
       " 'taxonomies',\n",
       " 'derived',\n",
       " 'from',\n",
       " 'analysis',\n",
       " 'existing',\n",
       " 'domain',\n",
       " 'its',\n",
       " 'instance',\n",
       " 'data',\n",
       " 'well',\n",
       " 'experience',\n",
       " 'gained',\n",
       " 'Part',\n",
       " '1',\n",
       " '\"',\n",
       " 'can',\n",
       " 'be',\n",
       " 'largely',\n",
       " 'automated',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'while',\n",
       " 'part',\n",
       " '2',\n",
       " 'deriving',\n",
       " 'performed',\n",
       " 'experts',\n",
       " 'Ideally',\n",
       " 'these',\n",
       " 'two',\n",
       " 'combined',\n",
       " 'build',\n",
       " 'based',\n",
       " 'on',\n",
       " 'given',\n",
       " 'A',\n",
       " 'scope',\n",
       " 'calculated',\n",
       " 'means',\n",
       " 'reference',\n",
       " 'text',\n",
       " 'corpus',\n",
       " 'so',\n",
       " '-',\n",
       " 'called',\n",
       " '“',\n",
       " 'key',\n",
       " 'questions',\n",
       " ',”',\n",
       " 'which',\n",
       " 'specified',\n",
       " 'potential',\n",
       " 'business',\n",
       " 'users']"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "6a7267efbf6fadf323e6919ae49483da79d63800eb323ed7cd34ea2e36e2688e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}